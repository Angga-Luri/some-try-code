{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBSManr4Muxr4vgGSUYLfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angga-Luri/some-try-code/blob/main/create_Dataset_Vehicle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v3OBMRntrqff"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib\n",
        "import os\n",
        "from PIL import Image\n",
        "from numpy import *\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 100, 100\n",
        "\n",
        "# number of channels\n",
        "img_channels = 1"
      ],
      "metadata": {
        "id": "e2pM0SFuAqip"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google = !if [ -d 'GDrive/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (google[0] is '0' ):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/GDrive/')\n",
        "!if [ -d 'GDrive/' ]; then echo \"Connection to Google drive successful\" ; else echo \"Error to connect to Google drive\"; fi\n"
      ],
      "metadata": {
        "id": "6lE-MEKpA9Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68b8374-9cb9-4d5f-a0c9-272e91c53393"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-6-2ba441986d59>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if (google[0] is '0' ):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/GDrive/\n",
            "Connection to Google drive successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train' ]; then echo \"Directory train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train' && echo \"Directory train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid' ]; then echo \"Directory valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid' && echo \"Directory valid created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/tmp' ]; then echo \"Directory tmp already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/tmp' && echo \"Directory tmp created\"; fi\n",
        "print (\"\")\n",
        "print (os.listdir(\"GDrive/My Drive/UNUSIDA/dataset/\"))\n",
        "print (\"\")\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train/type1' ]; then echo \"Directory type1 in train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train/type1' && echo \"Directory type1 in train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train/type2' ]; then echo \"Directory type2 in train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train/type2' && echo \"Directory type2 in train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train/type3' ]; then echo \"Directory type3 in train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train/type3' && echo \"Directory type3 in train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train/type4' ]; then echo \"Directory type4 in train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train/type4' && echo \"Directory type4 in train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/train/type5' ]; then echo \"Directory type5 in train already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/train/type5' && echo \"Directory type5 in train created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid/type1' ]; then echo \"Directory type1 in valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid/type1' && echo \"Directory type1 in valid created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid/type2' ]; then echo \"Directory type2 in valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid/type2' && echo \"Directory type2 in valid created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid/type3' ]; then echo \"Directory type3 in valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid/type3' && echo \"Directory type3 in valid created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid/type4' ]; then echo \"Directory type4 in valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid/type4' && echo \"Directory type4 in valid created\"; fi\n",
        "!if [ -d 'GDrive/My Drive/UNUSIDA/Dataset/valid/type5' ]; then echo \"Directory type5 in valid already exist\" ; else mkdir 'GDrive/My Drive/UNUSIDA/Dataset/valid/type5' && echo \"Directory type5 in valid created\"; fi\n",
        "print (\"\")\n",
        "# print (\"Deleting folder content train accident\")\n",
        "# !rm GDrive/My\\ Drive/CarCrashDetection/Dataset/train/accident/* > /dev/null\n",
        "# print (\"Deleting folder content train no_accident\")\n",
        "# !rm GDrive/My\\ Drive/CarCrashDetection/Dataset/train/no_accident/* > /dev/null\n",
        "# print (\"Deleting folder content valid accident\")\n",
        "# !rm GDrive/My\\ Drive/CarCrashDetection/Dataset/valid/accident/* > /dev/null\n",
        "# print (\"Deleting folder content valid no_accident\")\n",
        "# !rm GDrive/My\\ Drive/CarCrashDetection/Dataset/valid/no_accident/* > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8T6NdJRD47",
        "outputId": "eda4eb1d-4e2a-4435-8809-a5349dd9118f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory train already exist\n",
            "Directory valid already exist\n",
            "Directory tmp already exist\n",
            "\n",
            "['type4', 'type2', 'type3', 'type1', 'type5']\n",
            "\n",
            "Directory type1 in train already exist\n",
            "Directory type2 in train already exist\n",
            "Directory type3 in train already exist\n",
            "Directory type4 in train already exist\n",
            "Directory type5 in train already exist\n",
            "Directory type1 in valid already exist\n",
            "Directory type2 in valid already exist\n",
            "Directory type3 in valid already exist\n",
            "Directory type4 in valid already exist\n",
            "Directory type5 in valid already exist\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH = 'GDrive/My Drive/UNUSIDA/dataset/'\n",
        "filenames_type1 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type1/\")\n",
        "filenames_type2 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type2/\")\n",
        "filenames_type3 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type3/\")\n",
        "filenames_type4 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type4/\")\n",
        "filenames_type5 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type5/\")\n",
        "\n",
        "\n",
        "\n",
        "print (os.listdir('GDrive/My Drive/UNUSIDA/dataset'))\n",
        "num_type1 = len(filenames_type1)\n",
        "num_type2 = len(filenames_type2)\n",
        "num_type3 = len(filenames_type3)\n",
        "num_type4 = len(filenames_type4)\n",
        "num_type5 = len(filenames_type5)\n",
        "# filenames_no_accident = os.listdir (\"GDrive/My Drive/CarCrashDetection/Sources/frames/no_accident\")\n",
        "# num_no_accident = len(filenames_no_accident)\n",
        "\n",
        "print (\"Total images with type1 \", num_type1)\n",
        "print (\"Total images with type2 \", num_type2)\n",
        "print (\"Total images with type3 \", num_type3)\n",
        "print (\"Total images with type4 \", num_type4)\n",
        "print (\"Total images with type5 \", num_type5)\n",
        "# print (\"Total images without accident \", num_no_accident)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xktdnOhnBUSk",
        "outputId": "533e44ba-b2f6-419e-f1da-0bdf4ced89d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['type4', 'type2', 'type3', 'type1', 'type5']\n",
            "Total images with type1  100\n",
            "Total images with type2  100\n",
            "Total images with type3  100\n",
            "Total images with type4  100\n",
            "Total images with type5  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = 0\n",
        "\n",
        "if (data_augmentation == 1):\n",
        " \n",
        "  PATH_type1 = PATH + \"/type1/\"\n",
        "  remove = PATH_type1+\"_flip_*\"  \n",
        "  print(\"Deleting old mirrored images\")\n",
        "  !rm {remove}\n",
        "\n",
        "  print(\"Creating new mirrored images\")\n",
        "  for fn in filenames_type1:\n",
        "    img = mpimg.imread(PATH_type1+fn)\n",
        "    rimg= cv2.flip(img,1)\n",
        "    plt.imsave(\"%s%s%s.png\" % (PATH_type1,\"_flip_\", fn[:-4]), rimg) # saves images to frame folder\n",
        "\n",
        "PATH = 'GDrive/My Drive/UNUSIDA/dataset/'\n",
        "filenames_type1 = os.listdir (\"GDrive/My Drive/UNUSIDA/dataset/type1\")\n",
        "\n",
        "print (os.listdir('GDrive/My Drive/UNUSIDA/dataset/'))\n",
        "num_type1 = len(filenames_type1)\n",
        "# filenames_no_accident = os.listdir (\"GDrive/My Drive/CarCrashDetection/Sources/frames/no_accident\")\n",
        "# num_no_accident = len(filenames_no_accident)\n",
        "\n",
        "print (\"Total images with type1 \", num_type1)\n",
        "# print (\"Total images without accident \", num_no_accident)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJxBnacORIbS",
        "outputId": "4a5887fa-ef04-430f-9e31-42d3a1ad9a3a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['type4', 'type2', 'type3', 'type1', 'type5']\n",
            "Total images with type1  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_of_train = 0.8    # 80% = 0.8\n",
        "\n",
        "def split_dataset_in_train_and_valid( filenames, percentage):\n",
        "  \n",
        "  total_images = len(filenames)\n",
        "  total_train = int(total_images * percentage_of_train)\n",
        "  \n",
        "  set_train = []\n",
        "  \n",
        "  while (len(set_train) != total_train):     \n",
        "    num_image = random.randrange(total_images)\n",
        "    if num_image not in set_train:\n",
        "      set_train.append(num_image)\n",
        "\n",
        "  set_valid = []\n",
        "  for i in range(total_images):\n",
        "    if i not in set_train:\n",
        "      set_valid.append(i)\n",
        "    \n",
        "  images_train =[]\n",
        "  for i in set_train:    \n",
        "    images_train.append(filenames[i])\n",
        "   \n",
        "  images_valid =[]\n",
        "  for i in set_valid:    \n",
        "    images_valid.append(filenames[i])\n",
        "  \n",
        "  return (images_train, images_valid)"
      ],
      "metadata": {
        "id": "JiFs7kDSLaHa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type1_train_valid = (split_dataset_in_train_and_valid (filenames_type1 , percentage_of_train))\n",
        "type2_train_valid = (split_dataset_in_train_and_valid (filenames_type2 , percentage_of_train))\n",
        "type3_train_valid = (split_dataset_in_train_and_valid (filenames_type3 , percentage_of_train))\n",
        "type4_train_valid = (split_dataset_in_train_and_valid (filenames_type4 , percentage_of_train))\n",
        "type5_train_valid = (split_dataset_in_train_and_valid (filenames_type5 , percentage_of_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "M4xsWkh9QCSK",
        "outputId": "b7b92894-b80a-4be4-cc1d-26d70806f990"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1e9620a21361>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype1_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dataset_in_train_and_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilenames_type1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype2_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dataset_in_train_and_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilenames_type2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtype3_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dataset_in_train_and_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilenames_type3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtype4_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dataset_in_train_and_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilenames_type4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtype5_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dataset_in_train_and_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilenames_type5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c4459fe5aa2e>\u001b[0m in \u001b[0;36msplit_dataset_in_train_and_valid\u001b[0;34m(filenames, percentage)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtotal_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnum_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_image\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'randrange'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path = Path(\"data/\")\n",
        "# image_path = data_path / \"vehicle_type\""
      ],
      "metadata": {
        "id": "Aupl8XJJtmAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if image_path.is_dir():\n",
        "#     print(f\"{image_path} directory exists.\")\n",
        "# else:\n",
        "#     print(f\"Did not find {image_path} directory, creating one...\")\n",
        "#     image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "#     # Download pizza, steak, sushi data\n",
        "#     with open(data_path / \"dataset_resize.rar\", \"wb\") as f:\n",
        "#         request = requests.get(\"https://github.com/Angga-Luri/dataset/blob/main/dataset_resize.rar\")\n",
        "#         print(\"Downloading vehicle, 1, 2, 3, 4, 5 data...\")\n",
        "#         f.write(request.content)\n",
        "\n",
        "#     # Unzip pizza, steak, sushi data\n",
        "#     with zipfile.ZipFile(data_path / \"dataset_resize.rar\", \"r\") as zip_ref:\n",
        "#         print(\"Unzipping vehicle, data...\") \n",
        "#         zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "iNN0PIaAtrvw",
        "outputId": "93f2660f-c18d-47f2-f68b-0804f4dc99a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/vehicle_type directory, creating one...\n",
            "Downloading vehicle, 1, 2, 3, 4, 5 data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0d499b4cc836>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Unzip pizza, steak, sushi data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"dataset_resize.rar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unzipping vehicle, data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    }
  ]
}